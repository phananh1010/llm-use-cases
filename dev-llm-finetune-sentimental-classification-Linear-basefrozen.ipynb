{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0dfaf7-3bfd-487d-aea7-a3120ef09b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this code is the aggregation of many code, probably won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba082d6e-462e-4d8c-b4cd-4badd0264671",
   "metadata": {},
   "source": [
    "# Train hello-world dataset with imdb using facebook/opt-350m\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83dd9415-a8f8-4d43-9b9e-a4b0a727de65",
   "metadata": {},
   "source": [
    "dataset: use random 10% of imdb dataset, (seed=42)\n",
    "\n",
    "\n",
    "Linear layer:\n",
    "\n",
    "Recorded training: 205 seconds, 0.218 seconds per batch of batch size = 8\n",
    "Memory usage:  6342MiB\n",
    "Accuracy = 0.7504 #note: this is even lower than regular model with LSTM\n",
    "\n",
    "Note: baseline LSTM RNN is .87 (https://www.kaggle.com/code/getanmolgupta01/imdb-sentiments-analysis-rnn-lstm-gru)\n",
    "\t        precision\trecall\tf1-score\tsupport\n",
    "0\t        0.894593\t0.848202\t0.870780\t5033.00000\n",
    "1\t        0.851506\t0.897011\t0.873666\t4884.00000\n",
    "accuracy\t0.872240\t0.872240\t0.872240\t0.87224\n",
    "macro avg\t0.873050\t0.872606\t0.872223\t9917.00000\n",
    "weighted avg\t0.873374\t0.872240\t0.872202\t9917.00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393af8c4-c449-47ea-850f-a865a26ce181",
   "metadata": {},
   "source": [
    "## Declare library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04494204-7ec9-4dbb-9672-a81933e9337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "#from transformers import Trainer, TrainingArguments, \n",
    "\n",
    "\n",
    "\n",
    "MAX_LENGTH = 512 # length of the input \n",
    "DATA_PORTION = .1 # we use some % of the whole to imporve development speed. will set to 1.0 when the code is stable\n",
    "DATASET_SEED = 42# seed to randomize dataset\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1cf9a-d61d-4256-b491-3eecf63760fd",
   "metadata": {},
   "source": [
    "## load dataset\n",
    "#### NOTE: to learn more about a structure of the dataset and dataloader, refer to `investigate_dataloader.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd49daef-8f3a-4b68-b88c-eecd22d4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "dataset = load_dataset('imdb')\n",
    "train_dataset = dataset['train'].train_test_split(test_size=DATA_PORTION, shuffle=True, seed=DATASET_SEED)['test']\n",
    "test_dataset = dataset['test'].train_test_split(test_size=DATA_PORTION, shuffle=True, seed=DATASET_SEED)['test']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bdb37-8c75-40e2-ba07-3ba38838ae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668df527-3a58-4246-9267-89d9a4c2b792",
   "metadata": {},
   "source": [
    "## Load the tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70be6207-1050-40c2-a189-c2cd68caeabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "model_name = \"facebook/opt-350m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af28c6b-b1d3-44ec-aebd-916d44665043",
   "metadata": {},
   "source": [
    "## Modify last decision layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "495818ec-d1f0-4667-9590-401f7d7fd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden size of last layer: 1024\n"
     ]
    }
   ],
   "source": [
    "hidden_size = model.config.hidden_size\n",
    "print (f'hidden size of last layer: {hidden_size}')\n",
    "# Define a new linear layer\n",
    "model.classifier = torch.nn.Linear(hidden_size, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319426b-ca6a-4572-b6eb-6a1eca1c0ec5",
   "metadata": {},
   "source": [
    "# FREEZE the base layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbab104b-6e19-4797-b285-db450eea1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e25340-5db6-4893-8c18-b2bbc0579f0c",
   "metadata": {},
   "source": [
    "## Examine the tokenizer (more detail refer to `investigate_tokenizer.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cc1e6-ed31-4f9d-afee-16d36af7fb5d",
   "metadata": {},
   "source": [
    "## Use tokenizer to create tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c29b861-60ba-43ba-a3c1-45c3e129e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset and include labels\n",
    "def preprocess(examples):\n",
    "    result = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "    result['labels'] = examples['label']\n",
    "    return result\n",
    "\n",
    "if 'tokenized_train' not in globals():\n",
    "    tokenized_train = train_dataset.map(preprocess, batched=True)\n",
    "if 'tokenized_test' not in globals():\n",
    "    tokenized_test  = test_dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Convert datasets to PyTorch tensors\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d76d19-3d94-43cd-aa45-85a41ba67b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this commented code if we want to delete tokenized train/test \n",
    "# del tokenized_train\n",
    "# del tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdad94-3c35-445e-8c1a-48b3b8ab63f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f59e78c6-7765-4f63-9684-7284f44b9f7d",
   "metadata": {},
   "source": [
    "#### Examine fields in tokenized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bc2b55e-4602-4fc3-b312-07df4f7ae8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask', 'labels']), 512, tensor(1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0].keys(), len(tokenized_train[0]['input_ids']), tokenized_train[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f096b9-0770-4b91-83fc-1785ab6fc6b5",
   "metadata": {},
   "source": [
    "#### Create train/test loader with batch_size from tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf0af6e-7aa1-4053-aef2-644886ca8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(tokenized_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(tokenized_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5e43a-f727-4b72-816a-f4cd5503bf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78cb95b-be13-4bb8-850e-65443eedb96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24553a5c-604f-4481-83fa-2ceba7154ebf",
   "metadata": {},
   "source": [
    "## Full implementation of training iteration.\n",
    "##### We used detailed implementation for fine grain control of the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ba64-5fb8-46c8-81a9-55e5e3a2e4f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fbc4b-1ba2-4653-98ed-de371a3fa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a931d-74d2-4b91-8ac8-272f8457ec82",
   "metadata": {},
   "source": [
    "#### Implementation of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "719bd9a0-ce14-436e-9040-bb5f49274d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Calculate number of training steps\n",
    "num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f279fae7-c7ac-491c-80a1-fd650e944eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Move model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2880376f-f753-41e7-8e7b-eda4e168de7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=512, out_features=2, bias=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651e30c-711a-4c9d-9752-3829ccf3a202",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25f45b-b793-4b36-b1ad-a643fb17e1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b024333f-919c-427b-b54d-11392cbaa448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9624669add4d3194274a11216582ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 finished.\n",
      "Epoch 2/3 finished.\n",
      "Epoch 3/3 finished.\n",
      "Total training time: 205.39932346343994\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "btime = time.time()\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in train_dataloader:\n",
    "        # Move batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} finished.\")\n",
    "\n",
    "training_time = time.time() - btime\n",
    "print (f'Total training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d46aa12-dc3b-40a5-9a39-51cc109039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference per batch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3b3c282-e0c8-4a34-8e80-9b4617d004ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time per batch: 0.21874262349674115 seconds\n"
     ]
    }
   ],
   "source": [
    "print (f'Training time per batch: {training_time / num_training_steps} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2053f-2d8b-4a2e-9db9-0b34e1a7f53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89c0a8b-97dd-4035-a498-70973eda4527",
   "metadata": {},
   "source": [
    "#### Evaluation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5177c187-1df0-4dfe-810d-0cfca0015445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157deaa37a9e4a1aba71832cb5634a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.7504\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "num_testing_steps = 1 * len(test_dataloader) \n",
    "progress_bar_eval = tqdm(range(num_testing_steps))\n",
    "\n",
    "model.eval()\n",
    "accuracy = 0\n",
    "num_eval_steps = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy += (predictions == batch['labels']).float().mean().item()\n",
    "    num_eval_steps += 1\n",
    "\n",
    "    progress_bar_eval.update(1)\n",
    "\n",
    "accuracy = accuracy / num_eval_steps\n",
    "print(f\"Evaluation accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f164b3b-a9c4-45f2-83ac-5fdc6d551816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2708425c-534e-44af-8425-4fc465137607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 21 15:11:26 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40-24Q      On   | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   N/A    P8    N/A /  N/A |   6342MiB / 24370MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1022233      C   ...e/envs/env_llm/bin/python     4422MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2c34c-54bd-4a56-a531-77756c86887d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_llm)",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
