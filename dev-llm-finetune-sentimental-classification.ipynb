{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba082d6e-462e-4d8c-b4cd-4badd0264671",
   "metadata": {},
   "source": [
    "# Train hello-world dataset with imdb using facebook/opt-350m\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83dd9415-a8f8-4d43-9b9e-a4b0a727de65",
   "metadata": {},
   "source": [
    "dataset: use random 10% of imdb dataset, (seed=42)\n",
    "\n",
    "\n",
    "LORA:\n",
    "Recorded training: ? seconds, ? seconds per batch of batch size = 8\n",
    "memory footprint during training: 16376MiB\n",
    "accuracy: Evaluation accuracy: 0.8327\n",
    "\n",
    "Note: baseline LSTM RNN is .87 (https://www.kaggle.com/code/getanmolgupta01/imdb-sentiments-analysis-rnn-lstm-gru)\n",
    "\t        precision\trecall\tf1-score\tsupport\n",
    "0\t        0.894593\t0.848202\t0.870780\t5033.00000\n",
    "1\t        0.851506\t0.897011\t0.873666\t4884.00000\n",
    "accuracy\t0.872240\t0.872240\t0.872240\t0.87224\n",
    "macro avg\t0.873050\t0.872606\t0.872223\t9917.00000\n",
    "weighted avg\t0.873374\t0.872240\t0.872202\t9917.00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393af8c4-c449-47ea-850f-a865a26ce181",
   "metadata": {},
   "source": [
    "## Declare library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04494204-7ec9-4dbb-9672-a81933e9337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "#from transformers import Trainer, TrainingArguments, \n",
    "\n",
    "\n",
    "\n",
    "MAX_LENGTH = 512 # length of the input \n",
    "DATA_PORTION = .1 # we use some % of the whole to imporve development speed. will set to 1.0 when the code is stable\n",
    "DATASET_SEED = 42# seed to randomize dataset\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "learning_rate = 2e-5\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1cf9a-d61d-4256-b491-3eecf63760fd",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "#### NOTE: to learn more about a structure of the dataset and dataloader, refer to `investigate_dataloader.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd49daef-8f3a-4b68-b88c-eecd22d4865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "dataset = load_dataset('imdb')\n",
    "train_dataset = dataset['train'].train_test_split(test_size=DATA_PORTION, shuffle=True, seed=DATASET_SEED)['test']\n",
    "test_dataset = dataset['test'].train_test_split(test_size=DATA_PORTION, shuffle=True, seed=DATASET_SEED)['test']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bdb37-8c75-40e2-ba07-3ba38838ae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "668df527-3a58-4246-9267-89d9a4c2b792",
   "metadata": {},
   "source": [
    "## Load the tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70be6207-1050-40c2-a189-c2cd68caeabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model\n",
    "model_name = \"facebook/opt-350m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e25340-5db6-4893-8c18-b2bbc0579f0c",
   "metadata": {},
   "source": [
    "## Examine the tokenizer (more detail refer to `investigate_tokenizer.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cc1e6-ed31-4f9d-afee-16d36af7fb5d",
   "metadata": {},
   "source": [
    "## Use tokenizer to create tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c29b861-60ba-43ba-a3c1-45c3e129e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset and include labels\n",
    "def preprocess(examples):\n",
    "    result = tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    result['labels'] = examples['label']\n",
    "    return result\n",
    "\n",
    "if 'tokenized_train' not in globals():\n",
    "    tokenized_train = train_dataset.map(preprocess, batched=True)\n",
    "if 'tokenized_test' not in globals():\n",
    "    tokenized_test  = test_dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Convert datasets to PyTorch tensors\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d76d19-3d94-43cd-aa45-85a41ba67b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this commented code if we want to delete tokenized train/test \n",
    "# del tokenized_train\n",
    "# del tokenized_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdad94-3c35-445e-8c1a-48b3b8ab63f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f59e78c6-7765-4f63-9684-7284f44b9f7d",
   "metadata": {},
   "source": [
    "#### Examine fields in tokenized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc2b55e-4602-4fc3-b312-07df4f7ae8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask', 'labels']), 512, tensor(1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0].keys(), len(tokenized_train[0]['input_ids']), tokenized_train[0]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f096b9-0770-4b91-83fc-1785ab6fc6b5",
   "metadata": {},
   "source": [
    "#### Create train/test loader with batch_size from tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf0af6e-7aa1-4053-aef2-644886ca8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(tokenized_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(tokenized_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5e43a-f727-4b72-816a-f4cd5503bf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "381a8fb7-d346-44ac-9481-5f974ecabcb5",
   "metadata": {},
   "source": [
    "## Setting up training, short version"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdfc8950-de31-4501-9b4b-4f2d76a3faca",
   "metadata": {},
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78cb95b-be13-4bb8-850e-65443eedb96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24553a5c-604f-4481-83fa-2ceba7154ebf",
   "metadata": {},
   "source": [
    "## Full implementation of training iteration.\n",
    "##### We used detailed implementation for fine grain control of the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ba64-5fb8-46c8-81a9-55e5e3a2e4f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fbc4b-1ba2-4653-98ed-de371a3fa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8e2b1-0c5e-469d-b769-4cd567178dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c27a931d-74d2-4b91-8ac8-272f8457ec82",
   "metadata": {},
   "source": [
    "#### Implementation of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "719bd9a0-ce14-436e-9040-bb5f49274d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Calculate number of training steps\n",
    "num_training_steps = NUM_EPOCHS * len(train_dataloader)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f279fae7-c7ac-491c-80a1-fd650e944eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Move model to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2880376f-f753-41e7-8e7b-eda4e168de7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651e30c-711a-4c9d-9752-3829ccf3a202",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25f45b-b793-4b36-b1ad-a643fb17e1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b024333f-919c-427b-b54d-11392cbaa448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb05e4750caf438e9a5feae28a589302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 finished.\n",
      "Epoch 2/3 finished.\n",
      "Epoch 3/3 finished.\n",
      "Total training time: 642.9382650852203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "btime = time.time()\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch in train_dataloader:\n",
    "        # Move batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} finished.\")\n",
    "\n",
    "training_time = time.time() - btime\n",
    "print (f'Total training time: {training_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46aa12-dc3b-40a5-9a39-51cc109039c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89c0a8b-97dd-4035-a498-70973eda4527",
   "metadata": {},
   "source": [
    "#### Evaluation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5177c187-1df0-4dfe-810d-0cfca0015445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed93ddab10646b892a2c73640e9003b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.9257\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "num_testing_steps = 1 * len(test_dataloader) \n",
    "progress_bar_eval = tqdm(range(num_testing_steps))\n",
    "\n",
    "model.eval()\n",
    "accuracy = 0\n",
    "num_eval_steps = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    accuracy += (predictions == batch['labels']).float().mean().item()\n",
    "    num_eval_steps += 1\n",
    "\n",
    "    progress_bar_eval.update(1)\n",
    "\n",
    "accuracy = accuracy / num_eval_steps\n",
    "print(f\"Evaluation accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f164b3b-a9c4-45f2-83ac-5fdc6d551816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b19e0ed-af49-40b5-9b8f-1be08e630579",
   "metadata": {},
   "source": [
    "## Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d9094-b5d4-419a-a00c-f23fe6f7e4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe12cc-d827-4e27-9703-9700a0efb367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cf188-55b4-4698-abec-6933444f1529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f916184-9860-47a8-815f-6ff0559e231b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452874ba-fb31-4592-82c6-8f2aaca3b432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66d396-81a5-4ea6-a0ef-844da3d76a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0e781-fa28-4912-b9b1-5d9fd70b94e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708425c-534e-44af-8425-4fc465137607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2c34c-54bd-4a56-a531-77756c86887d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_llm)",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
